{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement\n",
    "\n",
    "We have cell images , some of then have malaria parasite and other don't. <br> Its a simple classification problem with 2 labels. We will mark one with parasite as 1 and without as 0.<br> Instead of creating a CNN model from the scratch, we will use the pretrained model (transfer learning). For our current evaluation we will us RESNET."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps \n",
    "- Load the images of both the classes.\n",
    "- Evaluate the shape of the Images and try to reshape it , as all the images will not be of same shape.\n",
    "- Convert the image to the matrix (3 d matrix , with channel as 3).\n",
    "- Divide the datset in the training and validation set.\n",
    "- Use ImageDataGenerator to increase the number samples.\n",
    "- Use Pretrained RESNET model extend it and try to evalute the classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = '/Users/amitjain/personalProjects/Machine-Learning/data-sets/cell_images/'\n",
    "parasite_folder = 'Parasitized'\n",
    "uninfected_folder = 'Uninfected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH =  120\n",
    "HEIGHT = 120\n",
    "\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files with parasite cells\n",
    "# r = root, d = directory, f = file\n",
    "def load_data(path, label, data):\n",
    "    for r,d,f in os.walk(path):\n",
    "        for file in f:\n",
    "            if not file.endswith('db'):\n",
    "                complete_path = r + \"/\" + file\n",
    "                img = cv2.imread(complete_path)\n",
    "                converted_img = cv2.resize(img, (WIDTH, HEIGHT))\n",
    "                row = [[img.shape[0], img.shape[1], img.shape[2], complete_path,label, converted_img]]\n",
    "                temp = pd.DataFrame(row, columns=['width', 'height', 'channel', 'path', 'label', 'image'])\n",
    "                data  = data.append(temp, ignore_index=True)\n",
    "                \n",
    "    return data            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# panda dataframe to evalaute image dataset\n",
    "## NOTE -> Try to load CSV First, then \n",
    "data = pd.DataFrame(columns=['width', 'height', 'channel', 'path', 'label', 'image'])\n",
    "data = load_data(root_directory + parasite_folder, 1, data)\n",
    "data = load_data(root_directory + uninfected_folder, 0, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27558, 120, 120, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(data.image, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.width = data.width.astype(int)\n",
    "data.height = data.height.astype(int)\n",
    "data.channel = data.channel.astype(int)\n",
    "data.path = data.path.astype(str)\n",
    "data.label = data.label.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type of all the Coloumns width       int64\n",
      "height      int64\n",
      "channel     int64\n",
      "path       object\n",
      "label       int64\n",
      "image      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Data Type of all the Coloumns', data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(path_or_buf=root_directory + 'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_csv(root_directory + 'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>channel</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>/Users/amitjain/personalProjects/Machine-Learn...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[0 0 0]\\n  [0 0 0]\\n  [0 0 0]\\n  ...\\n  [0 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>118</td>\n",
       "      <td>3</td>\n",
       "      <td>/Users/amitjain/personalProjects/Machine-Learn...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[0 0 0]\\n  [0 0 0]\\n  [0 0 0]\\n  ...\\n  [0 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "      <td>/Users/amitjain/personalProjects/Machine-Learn...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[0 0 0]\\n  [0 0 0]\\n  [0 0 0]\\n  ...\\n  [0 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>/Users/amitjain/personalProjects/Machine-Learn...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[0 0 0]\\n  [0 0 0]\\n  [0 0 0]\\n  ...\\n  [0 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>91</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>/Users/amitjain/personalProjects/Machine-Learn...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[0 0 0]\\n  [0 0 0]\\n  [0 0 0]\\n  ...\\n  [0 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  width  height  channel  \\\n",
       "0           0    115     112        3   \n",
       "1           1    121     118        3   \n",
       "2           2    169     148        3   \n",
       "3           3    106     136        3   \n",
       "4           4     91     103        3   \n",
       "\n",
       "                                                path  label  \\\n",
       "0  /Users/amitjain/personalProjects/Machine-Learn...      1   \n",
       "1  /Users/amitjain/personalProjects/Machine-Learn...      1   \n",
       "2  /Users/amitjain/personalProjects/Machine-Learn...      1   \n",
       "3  /Users/amitjain/personalProjects/Machine-Learn...      1   \n",
       "4  /Users/amitjain/personalProjects/Machine-Learn...      1   \n",
       "\n",
       "                                               image  \n",
       "0  [[[0 0 0]\\n  [0 0 0]\\n  [0 0 0]\\n  ...\\n  [0 0...  \n",
       "1  [[[0 0 0]\\n  [0 0 0]\\n  [0 0 0]\\n  ...\\n  [0 0...  \n",
       "2  [[[0 0 0]\\n  [0 0 0]\\n  [0 0 0]\\n  ...\\n  [0 0...  \n",
       "3  [[[0 0 0]\\n  [0 0 0]\\n  [0 0 0]\\n  ...\\n  [0 0...  \n",
       "4  [[[0 0 0]\\n  [0 0 0]\\n  [0 0 0]\\n  ...\\n  [0 0...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data frame  (27558, 5)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the data frame ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>channel</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27558.000000</td>\n",
       "      <td>27558.000000</td>\n",
       "      <td>27558.000000</td>\n",
       "      <td>27558.0</td>\n",
       "      <td>27558.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13778.500000</td>\n",
       "      <td>132.983453</td>\n",
       "      <td>132.487154</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7955.453695</td>\n",
       "      <td>20.619650</td>\n",
       "      <td>20.015949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6889.250000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13778.500000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20667.750000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27557.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         width        height  channel         label\n",
       "count  27558.000000  27558.000000  27558.000000  27558.0  27558.000000\n",
       "mean   13778.500000    132.983453    132.487154      3.0      0.500000\n",
       "std     7955.453695     20.619650     20.015949      0.0      0.500009\n",
       "min        0.000000     40.000000     46.000000      3.0      0.000000\n",
       "25%     6889.250000    121.000000    121.000000      3.0      0.000000\n",
       "50%    13778.500000    130.000000    130.000000      3.0      0.500000\n",
       "75%    20667.750000    145.000000    142.000000      3.0      1.000000\n",
       "max    27557.000000    385.000000    394.000000      3.0      1.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa34d17240>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.width.hist(bins = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa5a2894a8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEjFJREFUeJzt3H+s3XV9x/HnewWxQV1bKjcNbVZcmkxmNyx30ITF3MlSSllWTDCBkLU4ki4OMs26zDKT4WQmuAQ1JA5TZ0fZFGT+CI3U1QZ7Y5YI0mqlRWS9w0ZqGxpWRKqJ29X3/jifK6f3c27v7b3n3PO9u89HcnK+3/f5nO95n0/vva9+f5wTmYkkSe1+rd8NSJKax3CQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lS5bx+NzBdS5cuzZUrV854Oz/96U+58MILZ97QLLHf3ppL/c6lXsF+e22q/R44cOClzHzzpAMzc07errjiiuyGffv2dWU7s8V+e2su9TuXes20316bar/A/pzC31gPK0mSKoaDJKliOEiSKoaDJKliOEiSKoaDJKliOEiSKoaDJKliOEiSKnP26zPmi5XbHjtjfevqUW4dV2uSo/dc3+8WJHWBew6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpMqk4RARKyJiX0Q8GxHPRMT7Sn1JROyNiCPlfnGpR0TcFxEjEfF0RKxp29bmMv5IRGxuq18REYfKc+6LiOjFm5UkTc1U9hxGga2Z+VZgLXB7RFwGbAMez8xVwONlHeA6YFW5bQHuh1aYAHcBVwFXAneNBUoZs6Xteetn/tYkSdM1aThk5onM/HZZfhV4FrgE2AjsLMN2AjeU5Y3Ag9nyBLAoIpYB1wJ7M/NUZr4M7AXWl8felJnfzMwEHmzbliSpD87pnENErATeDjwJDGTmCWgFCHBxGXYJ8ELb046V2tnqxzrUJUl9MuVvZY2INwBfBN6fmT85y2mBTg/kNOqdethC6/ATAwMDDA8PT9L15E6fPt2V7fTK1tWjZ6wPLKxrTTJ+Lps+v+PNpX7nUq9gv73W7X6nFA4RcT6tYPhsZn6plF+MiGWZeaIcGjpZ6seAFW1PXw4cL/WhcfXhUl/eYXwlM7cD2wEGBwdzaGio07BzMjw8TDe20yvjv5576+pR7j3U3G9aP3rL0BnrTZ/f8eZSv3OpV7DfXut2v1O5WimAzwDPZubH2h7aBYxdcbQZeLStvqlctbQWeKUcdtoDrIuIxeVE9DpgT3ns1YhYW15rU9u2JEl9MJX/gl4N/AlwKCIOltrfAPcAj0TEbcAPgXeXx3YDG4AR4GfAewAy81RE3A08VcZ9ODNPleX3Ag8AC4GvlpskqU8mDYfM/A86nxcAuKbD+ARun2BbO4AdHer7gbdN1oskaXb4CWlJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVJg2HiNgREScj4nBb7UMR8aOIOFhuG9oeuzMiRiLiuYi4tq2+vtRGImJbW/3SiHgyIo5ExOcj4nXdfIOSpHM3lT2HB4D1Heofz8zLy203QERcBtwE/HZ5zj9GxIKIWAB8ErgOuAy4uYwF+GjZ1irgZeC2mbwhSdLMTRoOmfkN4NQUt7cReDgzf56ZPwBGgCvLbSQzn8/M/wEeBjZGRADvBL5Qnr8TuOEc34MkqcvOm8Fz74iITcB+YGtmvgxcAjzRNuZYqQG8MK5+FXAR8OPMHO0wvhIRW4AtAAMDAwwPD8+g/ZbTp093ZTu9snX16BnrAwvrWpOMn8umz+94c6nfudQr2G+vdbvf6YbD/cDdQJb7e4E/BaLD2KTzHkqeZXxHmbkd2A4wODiYQ0ND59R0J8PDw3RjO71y67bHzljfunqUew/NJNN76+gtQ2esN31+x5tL/c6lXsF+e63b/U7rr0xmvji2HBGfBr5SVo8BK9qGLgeOl+VO9ZeARRFxXtl7aB8vSeqTaV3KGhHL2lbfBYxdybQLuCkiLoiIS4FVwLeAp4BV5cqk19E6ab0rMxPYB9xYnr8ZeHQ6PUmSumfSPYeIeAgYApZGxDHgLmAoIi6ndQjoKPBnAJn5TEQ8AnwPGAVuz8xflO3cAewBFgA7MvOZ8hIfAB6OiL8HvgN8pmvvTpI0LZOGQ2be3KE84R/wzPwI8JEO9d3A7g7152ldzSRJagg/IS1JqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqkwaDhGxIyJORsThttqSiNgbEUfK/eJSj4i4LyJGIuLpiFjT9pzNZfyRiNjcVr8iIg6V59wXEdHtNylJOjdT2XN4AFg/rrYNeDwzVwGPl3WA64BV5bYFuB9aYQLcBVwFXAncNRYoZcyWtueNfy1J0iybNBwy8xvAqXHljcDOsrwTuKGt/mC2PAEsiohlwLXA3sw8lZkvA3uB9eWxN2XmNzMzgQfbtiVJ6pPzpvm8gcw8AZCZJyLi4lK/BHihbdyxUjtb/ViHekcRsYXWXgYDAwMMDw9Ps/3XnD59uivb6ZWtq0fPWB9YWNeaZPxcNn1+x5tL/c6lXsF+e63b/U43HCbS6XxBTqPeUWZuB7YDDA4O5tDQ0DRaPNPw8DDd2E6v3LrtsTPWt64e5d5D3f5n656jtwydsd70+R1vLvU7l3oF++21bvc73auVXiyHhCj3J0v9GLCibdxy4Pgk9eUd6pKkPppuOOwCxq442gw82lbfVK5aWgu8Ug4/7QHWRcTiciJ6HbCnPPZqRKwtVyltatuWJKlPJj0+EREPAUPA0og4Ruuqo3uARyLiNuCHwLvL8N3ABmAE+BnwHoDMPBURdwNPlXEfzsyxk9zvpXVF1ELgq+UmSeqjScMhM2+e4KFrOoxN4PYJtrMD2NGhvh9422R9SJJmj5+QliRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVZhQOEXE0Ig5FxMGI2F9qSyJib0QcKfeLSz0i4r6IGImIpyNiTdt2NpfxRyJi88zekiRpps7rwjb+IDNfalvfBjyemfdExLay/gHgOmBVuV0F3A9cFRFLgLuAQSCBAxGxKzNf7kJvmmUrtz12xvrW1aPcOq7WFEfvub7fLUiN1YvDShuBnWV5J3BDW/3BbHkCWBQRy4Brgb2ZeaoEwl5gfQ/6kiRN0UzDIYGvRcSBiNhSagOZeQKg3F9c6pcAL7Q991ipTVSXJPXJTA8rXZ2ZxyPiYmBvRHz/LGOjQy3PUq830AqgLQADAwMMDw+fY7u106dPd2U7vbJ19egZ6wML61qTNbnfTv/uTf95aDeXegX77bVu9zujcMjM4+X+ZER8GbgSeDEilmXmiXLY6GQZfgxY0fb05cDxUh8aVx+e4PW2A9sBBgcHc2hoqNOwczI8PEw3ttMr44/Xb109yr2HunGqaHY0ud+jtwxVtab/PLSbS72C/fZat/ud9mGliLgwIt44tgysAw4Du4CxK442A4+W5V3ApnLV0lrglXLYaQ+wLiIWlyub1pWaJKlPZvJfugHgyxExtp3PZea/R8RTwCMRcRvwQ+DdZfxuYAMwAvwMeA9AZp6KiLuBp8q4D2fmqRn0JUmaoWmHQ2Y+D/xuh/p/A9d0qCdw+wTb2gHsmG4vkqTu8hPSkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqTKef1uoB9WbnvsV8tbV49ya9u6JMk9B0lSB40Jh4hYHxHPRcRIRGzrdz+SNJ81IhwiYgHwSeA64DLg5oi4rL9dSdL81ZRzDlcCI5n5PEBEPAxsBL7X1670/9rKDueamnwO6ug91/e7Bc0jjdhzAC4BXmhbP1ZqkqQ+aMqeQ3SoZTUoYguwpayejojnZvrCfwFLgZdmup3ZYr+91eR+46NVqbG9TsB+e2uq/f7GVDbWlHA4BqxoW18OHB8/KDO3A9u7+cIRsT8zB7u5zV6y396aS/3OpV7Bfnut2/025bDSU8CqiLg0Il4H3ATs6nNPkjRvNWLPITNHI+IOYA+wANiRmc/0uS1JmrcaEQ4Ambkb2N2Hl+7qYapZYL+9NZf6nUu9gv32WncPuWdW530lSfNcU845SJIaZN6FQ0QcjYhDEXEwIvaX2pKI2BsRR8r94j72tyMiTkbE4bZax/6i5b7ylSNPR8SahvT7oYj4UZnjgxGxoe2xO0u/z0XEtbPc64qI2BcRz0bEMxHxvlJv5Pyepd/GzW9EvD4ivhUR3y29/l2pXxoRT5a5/Xy54ISIuKCsj5THV85Wr5P0+0BE/KBtbi8v9b7/rpU+FkTEdyLiK2W9d/ObmfPqBhwFlo6r/QOwrSxvAz7ax/7eAawBDk/WH7AB+Cqtz4msBZ5sSL8fAv6qw9jLgO8CFwCXAv8FLJjFXpcBa8ryG4H/LD01cn7P0m/j5rfM0RvK8vnAk2XOHgFuKvVPAe8ty38OfKos3wR8fpbndqJ+HwBu7DC+779rpY+/BD4HfKWs92x+592ewwQ2AjvL8k7ghn41kpnfAE6NK0/U30bgwWx5AlgUEctmp9OWCfqdyEbg4cz8eWb+ABih9dUpsyIzT2Tmt8vyq8CztD6J38j5PUu/E+nb/JY5Ol1Wzy+3BN4JfKHUx8/t2Jx/AbgmIjp9GLYnztLvRPr+uxYRy4HrgX8q60EP53c+hkMCX4uIA9H6xDXAQGaegNYvJHBx37rrbKL+mvy1I3eU3e8dbYfpGtNv2c1+O63/MTZ+fsf1Cw2c33LI4yBwEthLa8/lx5k52qGfX/VaHn8FuGi2eu3Ub2aOze1Hytx+PCIuGN9v0Y+fhU8Afw38sqxfRA/ndz6Gw9WZuYbWN8DeHhHv6HdDMzClrx3pg/uB3wQuB04A95Z6I/qNiDcAXwTen5k/OdvQDrUm9NvI+c3MX2Tm5bS+4eBK4K1n6afvczu+34h4G3An8FvA7wFLgA+U4X3tNyL+CDiZmQfayx2Gdm1+5104ZObxcn8S+DKtH+IXx3YRy/3J/nXY0UT9TelrR2ZbZr5YfvF+CXya1w5t9L3fiDif1h/az2bml0q5sfPbqd8mz2/p78fAMK1j84siYuzzVO39/KrX8vivM/XDk13V1u/6cigvM/PnwD/TnLm9GvjjiDgKPEzrcNIn6OH8zqtwiIgLI+KNY8vAOuAwra/q2FyGbQYe7U+HE5qov13ApnIlxVrglbHDI/007ljsu2jNMbT6valcSXEpsAr41iz2FcBngGcz82NtDzVyfifqt4nzGxFvjohFZXkh8Ie0zpHsA24sw8bP7dic3wh8PcvZ0z72+/22/yQEreP37XPbt5+FzLwzM5dn5kpaJ5i/npm30Mv5nY0z7E25AW+hdTXHd4FngA+W+kXA48CRcr+kjz0+ROtQwf/SSv/bJuqP1q7jJ2kd2z0EDDak338p/TxdfkiXtY3/YOn3OeC6We7192ntWj8NHCy3DU2d37P027j5BX4H+E7p6TDwt6X+FloBNQL8G3BBqb++rI+Ux98yy3M7Ub9fL3N7GPhXXruiqe+/a229D/Ha1Uo9m18/IS1Jqsyrw0qSpKkxHCRJFcNBklQxHCRJFcNBklQxHCRJFcNBklQxHCRJlf8Dcdf2tNS6f9IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.height.hist(bins = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information Decided from metadata\n",
    "\n",
    "- Since most of the width and height is btw 100-150 , we will reshape image around the same.\n",
    "- All the images are of same channel.\n",
    "- We have equal number of both the classes.\n",
    "- Data generated have to be shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_and_test(data_frame, training_percentage):\n",
    "    training_number = data_frame.shape[0] * training_percentage / 100\n",
    "    test_number = data_frame.shape[0] - training_number\n",
    "    return data_frame.head(int(training_number)), data_frame.tail(int(test_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shuffle(data)\n",
    "train, val = split_training_and_test(data, 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X = np.stack(train.image, axis=0) \n",
    "train_y = train.label\n",
    "\n",
    "val_X = np.stack(val.image, axis=0)  \n",
    "val_y = val.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Features (23424, 120, 120, 3)\n",
      "Shape of Validation Features (4133, 120, 120, 3)\n",
      "Shape of Training Labels (23424,)\n",
      "Shape of Validation Labels (4133,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Training Features', train_X.shape)\n",
    "print('Shape of Validation Features', val_X.shape)\n",
    "\n",
    "print('Shape of Training Labels', train_y.shape)\n",
    "print('Shape of Validation Labels', val_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Model Using Resnet\n",
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESNET_WEIGHTS_PATH = '/Users/amitjain/personalProjects/Machine-Learning/trained_model/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "RESNET50_POOLING_AVERAGE = 'avg'\n",
    "DENSE_LAYER_ACTIVATION = 'softmax'\n",
    "OBJECTIVE_FUNCTION = 'sparse_categorical_crossentropy'\n",
    "LOSS_METRICS = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "EARLY_STOP_PATIENCE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = RESNET_WEIGHTS_PATH))\n",
    "model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
    "\n",
    "model.layers[0].trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23424 samples, validate on 4133 samples\n",
      "Epoch 1/10\n",
      " 2368/23424 [==>...........................] - ETA: 3:47:52 - loss: 0.2983 - acc: 0.8826"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-8dc5ab3a50d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/Python_35/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda2/envs/Python_35/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/Python_35/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda2/envs/Python_35/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_y, \n",
    "          validation_data=(val_X, val_y), epochs=NUM_EPOCHS, batch_size = BATCH_SIZE, verbose =1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
