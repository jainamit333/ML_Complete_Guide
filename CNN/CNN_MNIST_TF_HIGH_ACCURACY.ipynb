{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focus \n",
    "We will try to lear about the CNN and compare it with traditional Neural Network for the result.\n",
    "For this problem we will take MNIST Data set from one of the Kaggle Competition.<br>\n",
    "Competetion URL : https://www.kaggle.com/c/digit-recognizer/data <br>\n",
    "Tags : Classification, CNN, Image Classification. </br>\n",
    "    \n",
    "GOAL: To improve the accuracy more than 99     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/amitjain/personalProjects/Machine-Learning/data-sets/digit-recognize/'\n",
    "train_file = 'train.csv'\n",
    "test_file = 'test.csv'\n",
    "data = pd.read_csv( data_dir + train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4132., 4684., 4177., 4351., 4072., 3795., 4137., 4401., 4063.,\n",
       "        4188.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data.label, bins=10, rwidth=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_and_test(data_frame, training_percentage):\n",
    "    training_number = data_frame.shape[0] * training_percentage / 100\n",
    "    test_number = data_frame.shape[0] - training_number\n",
    "    return data_frame.head(int(training_number)), data_frame.tail(int(test_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shuffle(data)\n",
    "train, val = split_training_and_test(data, 80)\n",
    "\n",
    "train_X = train.loc[:, train.columns !=  'label']\n",
    "train_y = train['label']\n",
    "\n",
    "val_X = val.loc[:, val.columns !=  'label']\n",
    "val_y = val['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amitjain/anaconda2/envs/Python_35/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/amitjain/anaconda2/envs/Python_35/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/amitjain/anaconda2/envs/Python_35/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "val_X = scaler.transform(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_mat = train_X.reshape(33600, 28, 28,1)\n",
    "val_X_mat = val_X.reshape(8400, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 24, 24, 12)        312       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 24, 24, 12)        48        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 8, 8, 16)          4816      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 120)               30840     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 84)                336       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 47,910\n",
      "Trainable params: 47,446\n",
      "Non-trainable params: 464\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(12,(5,5),strides=1,padding='valid', input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(16,(5,5),strides=1,padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(84,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(optimizer='AdaDelta',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "WARNING:tensorflow:From /Users/amitjain/anaconda2/envs/Python_35/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 75s 2ms/sample - loss: 0.5160 - acc: 0.8420 - val_loss: 0.1574 - val_acc: 0.9513\n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 76s 2ms/sample - loss: 0.1724 - acc: 0.9483 - val_loss: 0.0915 - val_acc: 0.9721\n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 78s 2ms/sample - loss: 0.1179 - acc: 0.9630 - val_loss: 0.0666 - val_acc: 0.9789\n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 80s 2ms/sample - loss: 0.0968 - acc: 0.9698 - val_loss: 0.0659 - val_acc: 0.9802\n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 84s 2ms/sample - loss: 0.0849 - acc: 0.9731 - val_loss: 0.0481 - val_acc: 0.9843\n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 84s 2ms/sample - loss: 0.0730 - acc: 0.9774 - val_loss: 0.0437 - val_acc: 0.9863\n",
      "Epoch 7/20\n",
      "33600/33600 [==============================] - 82s 2ms/sample - loss: 0.0676 - acc: 0.9786 - val_loss: 0.0397 - val_acc: 0.9869\n",
      "Epoch 8/20\n",
      "33600/33600 [==============================] - 83s 2ms/sample - loss: 0.0617 - acc: 0.9804 - val_loss: 0.0396 - val_acc: 0.9868\n",
      "Epoch 9/20\n",
      "33600/33600 [==============================] - 83s 2ms/sample - loss: 0.0574 - acc: 0.9816 - val_loss: 0.0386 - val_acc: 0.9877\n",
      "Epoch 10/20\n",
      "33600/33600 [==============================] - 84s 2ms/sample - loss: 0.0527 - acc: 0.9836 - val_loss: 0.0383 - val_acc: 0.9871\n",
      "Epoch 11/20\n",
      "33600/33600 [==============================] - 84s 3ms/sample - loss: 0.0525 - acc: 0.9834 - val_loss: 0.0362 - val_acc: 0.9888\n",
      "Epoch 12/20\n",
      "33600/33600 [==============================] - 84s 3ms/sample - loss: 0.0492 - acc: 0.9844 - val_loss: 0.0345 - val_acc: 0.9890\n",
      "Epoch 13/20\n",
      "33600/33600 [==============================] - 84s 2ms/sample - loss: 0.0452 - acc: 0.9850 - val_loss: 0.0378 - val_acc: 0.9889\n",
      "Epoch 14/20\n",
      "33600/33600 [==============================] - 84s 3ms/sample - loss: 0.0461 - acc: 0.9854 - val_loss: 0.0315 - val_acc: 0.9898\n",
      "Epoch 15/20\n",
      "33600/33600 [==============================] - 84s 3ms/sample - loss: 0.0430 - acc: 0.9867 - val_loss: 0.0288 - val_acc: 0.9913\n",
      "Epoch 16/20\n",
      "33600/33600 [==============================] - 85s 3ms/sample - loss: 0.0406 - acc: 0.9874 - val_loss: 0.0297 - val_acc: 0.9911\n",
      "Epoch 17/20\n",
      "33600/33600 [==============================] - 84s 3ms/sample - loss: 0.0403 - acc: 0.9868 - val_loss: 0.0299 - val_acc: 0.9905\n",
      "Epoch 18/20\n",
      "33600/33600 [==============================] - 85s 3ms/sample - loss: 0.0400 - acc: 0.9873 - val_loss: 0.0344 - val_acc: 0.9893\n",
      "Epoch 19/20\n",
      "33600/33600 [==============================] - 84s 3ms/sample - loss: 0.0346 - acc: 0.9888 - val_loss: 0.0316 - val_acc: 0.9900\n",
      "Epoch 20/20\n",
      "33600/33600 [==============================] - 86s 3ms/sample - loss: 0.0349 - acc: 0.9888 - val_loss: 0.0331 - val_acc: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a69f8d0f0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X_mat, train_y, validation_data=(val_X_mat, val_y), epochs=20, batch_size = 128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/Users/amitjain/personalProjects/Machine-Learning/Complete_Guide_Self/CNN/cnn_tf_log/lexnet.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv( data_dir + test_file)\n",
    "test_X = test_data.loc[:, test_data.columns !=  'label']\n",
    "test_X = scaler.transform(test_X)\n",
    "test_X_mat = test_X.reshape(28000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prediction = model.predict_classes(test_X_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(class_prediction)\n",
    "result['Label'] = result[0]\n",
    "result['ImageId'] = result.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(index=False, \n",
    "              path_or_buf='/Users/amitjain/personalProjects/Machine-Learning/Complete_Guide_Self/CNN/cnn_tf_log/submission.csv',\n",
    "             columns = ['ImageId', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "    \n",
    "    # Multiple convolution operations to detect features in the images\n",
    "    model.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(28,28,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,kernel_size=3,activation='relu')) # no need to specify shape as there is a layer before\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4)) # reduce overfitting\n",
    "\n",
    "    model.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4)) # reduce overfitting\n",
    "    \n",
    "    # Flattening and classification by standard ANN\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
